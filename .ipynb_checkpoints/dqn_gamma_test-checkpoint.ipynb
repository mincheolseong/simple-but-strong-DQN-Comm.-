{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-25T09:28:14.858Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode(train):100   DQN: 0.460   Time cost: 19.38s\n",
      "Episode(train):200   DQN: 0.586   Time cost: 21.15s\n",
      "Episode(train):300   DQN: 0.847   Time cost: 21.60s\n",
      "Episode(train):400   DQN: 0.825   Time cost: 21.51s\n",
      "Episode(train):500   DQN: 0.911   Time cost: 25.60s\n",
      "Episode(train):600   DQN: 0.966   Time cost: 25.89s\n",
      "Episode(train):700   DQN: 1.070   Time cost: 25.84s\n",
      "Episode(train):800   DQN: 0.957   Time cost: 25.74s\n",
      "Episode(train):900   DQN: 1.002   Time cost: 25.35s\n",
      "Episode(train):1000   DQN: 1.040   Time cost: 26.31s\n",
      "Episode(train):1100   DQN: 1.097   Time cost: 26.33s\n",
      "Episode(train):1200   DQN: 1.074   Time cost: 26.39s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Oct  7 14:36:08 2018\n",
    "\n",
    "@author: mengxiaomao / Email: mengxiaomaomao@outlook.com\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "reuse = tf.compat.v1.AUTO_REUSE\n",
    "dtype = np.float32\n",
    "flag_fig = True\n",
    "\n",
    "fd = 10\n",
    "Ts = 20e-3\n",
    "\n",
    "L = 2\n",
    "C = 16\n",
    "meanM = 2   # lamda: average user number in one BS\n",
    "minM = 4   # maximum user number in one BS\n",
    "maxM = 4   # maximum user number in one BS\n",
    "min_dis = 0.01 #km\n",
    "max_dis = 1. #km\n",
    "min_p = 5. #dBm\n",
    "max_p = 38. #dBm\n",
    "p_n = -114. #dBm\n",
    "\n",
    "power_num = 10 #action_num\n",
    "OBSERVE = 100\n",
    "EPISODE = 10000\n",
    "memory_size = 50000\n",
    "INITIAL_EPSILON = 0.2 \n",
    "FINAL_EPSILON = 0.0001 \n",
    "learning_rate = 0.001\n",
    "train_interval = 10\n",
    "batch_size = 256\n",
    "update_rate = 0.01\n",
    "\n",
    "c = 3*L*(L+1) + 1 # adjascent BS\n",
    "K = maxM * c # maximum adjascent users, including itself\n",
    "state_num = 3*C + 2    #  3*K - 1  3*C + 2\n",
    "\n",
    "\n",
    "sigma2_ = 1e-3*pow(10., p_n/10.)\n",
    "maxP = 1e-3*pow(10., max_p/10.)\n",
    "power_set = np.hstack([np.zeros((1), dtype=dtype), 1e-3*pow(10., np.linspace(min_p, max_p, power_num-1)/10.)])\n",
    "gamma = 0.3\n",
    "weight_file = os.getcwd() + '\\saved_networks\\dqn_03.mat'\n",
    "hist_file = 'C:\\Software\\workshop\\python\\Commsys\\saved_networks\\hist_03'\n",
    "replay_memory = deque(maxlen = memory_size)\n",
    "\n",
    "def Generate_H_set():\n",
    "    '''\n",
    "    Jakes model\n",
    "    '''\n",
    "    pho = np.float32(scipy.special.k0(2*np.pi*fd*Ts))\n",
    "    H_set = np.zeros([M,K,int(Ns)], dtype=dtype)\n",
    "    H_set[:,:,0] = np.kron(np.sqrt(0.5*(np.random.randn(M, c)**2+np.random.randn(M, c)**2)), np.ones((1,maxM), dtype=np.int32))\n",
    "    for i in range(1,int(Ns)):\n",
    "        H_set[:,:,i] = H_set[:,:,i-1]*pho + np.sqrt((1.-pho**2)*0.5*(np.random.randn(M, K)**2+np.random.randn(M, K)**2))\n",
    "    path_loss = Generate_path_loss()\n",
    "    H2_set = np.square(H_set) * np.tile(np.expand_dims(path_loss, axis=2), [1,1,int(Ns)])   \n",
    "    return H2_set\n",
    "    \n",
    "def Generate_environment():\n",
    "    path_matrix = M*np.ones((n_y + 2*L, n_x + 2*L, maxM), dtype = np.int32)\n",
    "    for i in range(L, n_y+L):\n",
    "        for j in range(L, n_x+L):\n",
    "            for l in range(maxM):\n",
    "                path_matrix[i,j,l] = ((i-L)*n_x + (j-L))*maxM + l\n",
    "    p_array = np.zeros((M, K), dtype = np.int32)\n",
    "    for n in range(N):\n",
    "        i = n//n_x\n",
    "        j = n%n_x\n",
    "        Jx = np.zeros((0), dtype = np.int32)\n",
    "        Jy = np.zeros((0), dtype = np.int32)\n",
    "        for u in range(i-L, i+L+1):\n",
    "            v = 2*L+1-np.abs(u-i)\n",
    "            jx = j - (v-i%2)//2 + np.linspace(0, v-1, num = v, dtype = np.int32) + L\n",
    "            jy = np.ones((v), dtype = np.int32)*u + L\n",
    "            Jx = np.hstack((Jx, jx))\n",
    "            Jy = np.hstack((Jy, jy))\n",
    "        for l in range(maxM):\n",
    "            for k in range(c):\n",
    "                for u in range(maxM):\n",
    "                    p_array[n*maxM+l,k*maxM+u] = path_matrix[Jy[k],Jx[k],u]\n",
    "    p_main = p_array[:,(c-1)//2*maxM:(c+1)//2*maxM]\n",
    "    for n in range(N):\n",
    "        for l in range(maxM):\n",
    "            temp = p_main[n*maxM+l,l]\n",
    "            p_main[n*maxM+l,l] = p_main[n*maxM+l,0]\n",
    "            p_main[n*maxM+l,0] = temp\n",
    "    p_inter = np.hstack([p_array[:,:(c-1)//2*maxM], p_array[:,(c+1)//2*maxM:]])\n",
    "    p_array =  np.hstack([p_main, p_inter])             \n",
    "     \n",
    "    user = np.maximum(np.minimum(np.random.poisson(meanM, (N)), maxM), minM)\n",
    "    user_list = np.zeros((N, maxM), dtype = np.int32)\n",
    "    for i in range(N):\n",
    "        user_list[i,:user[i]] = 1\n",
    "    for k in range(N):\n",
    "        for i in range(maxM):\n",
    "            if user_list[k,i] == 0.:\n",
    "                p_array = np.where(p_array == k*maxM+i, M, p_array)              \n",
    "    p_list = list()\n",
    "    for i in range(M):\n",
    "        p_list_temp = list() \n",
    "        for j in range(K):\n",
    "            p_list_temp.append([p_array[i,j]])\n",
    "        p_list.append(p_list_temp)               \n",
    "    return p_array, p_list, user_list\n",
    "\n",
    "def Generate_path_loss():\n",
    "    slope = 0.      #0.3\n",
    "    p_tx = np.zeros((n_y, n_x))\n",
    "    p_ty = np.zeros((n_y, n_x))\n",
    "    p_rx = np.zeros((n_y, n_x, maxM))\n",
    "    p_ry = np.zeros((n_y, n_x, maxM))   \n",
    "    dis_rx = np.random.uniform(min_dis, max_dis, size = (n_y, n_x, maxM))\n",
    "    phi_rx = np.random.uniform(-np.pi, np.pi, size = (n_y, n_x, maxM))    \n",
    "    for i in range(n_y):\n",
    "        for j in range(n_x):\n",
    "            p_tx[i,j] = 2*max_dis*j + (i%2)*max_dis\n",
    "            p_ty[i,j] = np.sqrt(3.)*max_dis*i\n",
    "            for k in range(maxM):  \n",
    "                p_rx[i,j,k] = p_tx[i,j] + dis_rx[i,j,k]*np.cos(phi_rx[i,j,k])\n",
    "                p_ry[i,j,k] = p_ty[i,j] + dis_rx[i,j,k]*np.sin(phi_rx[i,j,k])\n",
    "    dis = 1e10 * np.ones((M, K), dtype = dtype)\n",
    "    lognormal = np.zeros((M, K), dtype = dtype)\n",
    "    for k in range(N):\n",
    "        for l in range(maxM):\n",
    "            for i in range(c):\n",
    "                for j in range(maxM):\n",
    "                    if p_array[k*maxM+l,i*maxM+j] < M:\n",
    "                        bs = p_array[k*maxM+l,i*maxM+j]//maxM\n",
    "                        dx2 = np.square((p_rx[k//n_x][k%n_x][l]-p_tx[bs//n_x][bs%n_x]))\n",
    "                        dy2 = np.square((p_ry[k//n_x][k%n_x][l]-p_ty[bs//n_x][bs%n_x]))\n",
    "                        distance = np.sqrt(dx2 + dy2)\n",
    "                        dis[k*maxM+l,i*maxM+j] = distance\n",
    "                        std = 8. + slope * (distance - min_dis)\n",
    "                        lognormal[k*maxM+l,i*maxM+j] = np.random.lognormal(sigma = std)                   \n",
    "    path_loss = lognormal*pow(10., -(120.9 + 37.6*np.log10(dis))/10.)\n",
    "    return path_loss\n",
    "    \n",
    "def Calculate_rate():\n",
    "    maxC = 1000.\n",
    "    P_extend = tf.concat([P, tf.zeros((1), dtype=dtype)], axis=0)\n",
    "    P_matrix = tf.gather_nd(P_extend, p_list)\n",
    "    path_main = tf.multiply(H2[:,0], P_matrix[:,0])\n",
    "    path_inter = tf.reduce_sum(tf.multiply(H2[:,1:], P_matrix[:,1:]), axis=1)\n",
    "    sinr = path_main / (path_inter + sigma2)\n",
    "    sinr = tf.minimum(sinr, maxC)       #capped sinr\n",
    "    rate = W * tf.math.log(1. + sinr)/np.log(2)\n",
    "    rate_extend = tf.concat([rate, tf.zeros((1), dtype=dtype)], axis=0)\n",
    "    rate_matrix = tf.gather_nd(rate_extend, p_list)\n",
    "    sinr_norm_inv = H2[:,1:] / tf.tile(H2[:,0:1], [1,K-1])\n",
    "    sinr_norm_inv = tf.math.log(1. + sinr_norm_inv)/np.log(2)# log representation\n",
    "    reward = tf.reduce_sum(rate)\n",
    "    return rate_matrix, sinr_norm_inv, P_matrix, reward\n",
    "\n",
    "def Generate_state(rate_last, p_last, sinr_norm_inv):\n",
    "    '''\n",
    "    Generate state matrix\n",
    "    ranking\n",
    "    state including:\n",
    "    1.rate[t-1]          [M,K]  rate_last\n",
    "    2.power[t-1]         [M,K]  p_last\n",
    "    3.sinr_norm_inv[t]   [M,K-1]  sinr_norm_inv\n",
    "    '''\n",
    "    indices1 = np.tile(np.expand_dims(np.linspace(0, M-1, num=M, dtype=np.int32), axis=1),[1,C])\n",
    "    indices2 = np.argsort(sinr_norm_inv, axis = 1)[:,-C:]\n",
    "    rate_last = np.hstack([rate_last[:,0:1], rate_last[indices1, indices2+1]])\n",
    "    p_last = np.hstack([p_last[:,0:1], p_last[indices1, indices2+1]])\n",
    "    sinr_norm_inv = sinr_norm_inv[indices1, indices2]\n",
    "    s_t = np.hstack([rate_last, p_last, sinr_norm_inv])\n",
    "    return s_t\n",
    "    \n",
    "def Variable(shape):  \n",
    "    w = tf.compat.v1.get_variable('w', shape=shape, initializer = tf.compat.v1.truncated_normal_initializer(stddev=0.1))\n",
    "    b = tf.compat.v1.get_variable('b', shape=[shape[-1]], initializer = tf.constant_initializer(0.01))    \n",
    "    return w, b   \n",
    "    \n",
    "def Find_params(para_name):\n",
    "    sets=[]\n",
    "    for var in tf.compat.v1.trainable_variables():\n",
    "        if not var.name.find(para_name):\n",
    "            sets.append(var)\n",
    "    return sets\n",
    "    \n",
    "def Network(s, a, name):\n",
    "    with tf.compat.v1.variable_scope(name + '.0', reuse = reuse):\n",
    "        w,b = Variable([state_num, 128])\n",
    "        l = tf.nn.relu(tf.matmul(s, w)+b)\n",
    "    with tf.compat.v1.variable_scope(name + '.1', reuse = reuse):\n",
    "        w,b = Variable([128, 64])\n",
    "        l = tf.nn.relu(tf.matmul(l, w)+b)\n",
    "    with tf.compat.v1.variable_scope(name + '.2', reuse = reuse):\n",
    "        w,b = Variable([64, power_num])\n",
    "        q_hat = tf.matmul(l, w) + b\n",
    "    r = tf.compat.v1.reduce_sum(tf.multiply(q_hat, a), reduction_indices = 1)\n",
    "    a_hat = tf.argmax(q_hat, 1)\n",
    "    list_var = Find_params(name)\n",
    "    return q_hat, a_hat, r, list_var\n",
    "    \n",
    "def Loss(y, r):\n",
    "    cost = tf.reduce_mean(tf.square((y - r)))\n",
    "    return cost\n",
    "    \n",
    "def Optimizer(cost, var_list):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    lr = tf.compat.v1.train.exponential_decay(learning_rate, global_step = global_step,\n",
    "                                    decay_steps = EPISODE, decay_rate = 0.1)\n",
    "    add_global = global_step.assign_add(1)\n",
    "    with tf.compat.v1.variable_scope('opt', reuse = reuse):\n",
    "        train_op = tf.compat.v1.train.AdamOptimizer(learning_rate = lr).minimize(cost, var_list = var_list)\n",
    "    return train_op, add_global\n",
    "        \n",
    "def Save_store(s_t, a_t, r_t, s_next):\n",
    "    r_t = np.tile(r_t, (M))\n",
    "    p_t = np.zeros((M, power_num), dtype = dtype)\n",
    "    p_t[range(M), a_t] = 1.\n",
    "    for i in range(M):    \n",
    "        replay_memory.append((s_t[i], p_t[i], r_t[i], s_next[i]))\n",
    "    \n",
    "def Sample():\n",
    "    minibatch = random.sample(replay_memory, batch_size)\n",
    "    batch_s = [d[0] for d in minibatch]\n",
    "    batch_a = [d[1] for d in minibatch]\n",
    "    batch_r = [d[2] for d in minibatch]\n",
    "    batch_s_next = [d[3] for d in minibatch]\n",
    "    return batch_s, batch_a, batch_r, batch_s_next\n",
    "\n",
    "def Select_action(sess, s_t, episode):\n",
    "    if episode > OBSERVE:\n",
    "        epsilon = INITIAL_EPSILON - (episode - OBSERVE) * (INITIAL_EPSILON - FINAL_EPSILON) / (EPISODE - OBSERVE) \n",
    "    elif episode <= OBSERVE:\n",
    "        epsilon = INITIAL_EPSILON\n",
    "    else:\n",
    "        epsilon = 0.\n",
    "    q_hat_ = sess.run(q_main, feed_dict={s: s_t})\n",
    "    best_action = np.argmax(q_hat_, axis = 1)\n",
    "    random_index = np.array(np.random.uniform(size = (M)) < epsilon, dtype = np.int32)\n",
    "    random_action = np.random.randint(0, high = power_num, size = (M))\n",
    "    action_set = np.vstack([best_action, random_action])\n",
    "    power_index = action_set[random_index, range(M)]\n",
    "    power = power_set[power_index] # W\n",
    "    return power, power_index \n",
    "    \n",
    "def Step(p_t, H2_t):    \n",
    "    rate_last, sinr_norm_, p_last, reward_ = sess.run([rate_matrix, sinr_norm_inv, P_matrix, reward], \n",
    "        feed_dict={P: p_t, H2: H2_t, W: W_, sigma2: sigma2_}) \n",
    "    s_next = Generate_state(rate_last, p_last, sinr_norm_)\n",
    "    return s_next, reward_  \n",
    "    \n",
    "def Experience_replay(sess):\n",
    "    batch_s, batch_a, batch_r, batch_s_next = Sample()\n",
    "    a_main_, q_main_ = sess.run([a_main, q_main], feed_dict = {s : batch_s_next})\n",
    "    q_double = q_main_[range(batch_size), a_main_]\n",
    "    y_ = batch_r + gamma * q_double\n",
    "    sess.run(train_main, feed_dict = {s : batch_s, a : batch_a, y : y_})\n",
    "    sess.run(update)\n",
    "    \n",
    "def Network_update(list_main, list_targ):\n",
    "    update=[]\n",
    "    for i in range(len(list_targ)):\n",
    "        value = list_main[i].value() * update_rate + (1. - update_rate) * list_targ[i].value()\n",
    "        #update.append(tf.compat.v1.assign(tf.compat.v1.get_default_graph().get_tensor_by_name(list_targ[i].name), value))\n",
    "    return update\n",
    "\n",
    "def Initial_para():\n",
    "    H2_set = Generate_H_set()\n",
    "    s_next, _ = Step(np.zeros([M], dtype = dtype), H2_set[:,:,0])\n",
    "    return H2_set, s_next \n",
    "    \n",
    "def Train_episode(sess, episode): \n",
    "    reward_dqn_list = list()\n",
    "    H2_set, s_t = Initial_para()\n",
    "    for step_index in range(int(Ns)):\n",
    "        p_t, a_t = Select_action(sess, s_t, episode)\n",
    "        s_next, r_ = Step(p_t, H2_set[:,:,step_index])\n",
    "        Save_store(s_t, a_t, r_, s_next)\n",
    "        if episode > OBSERVE:\n",
    "            if step_index % train_interval == 0:\n",
    "                Experience_replay(sess)\n",
    "        s_t = s_next\n",
    "        reward_dqn_list.append(r_)\n",
    "    if episode > OBSERVE:\n",
    "        sess.run(add_global)\n",
    "    dqn_mean = sum(reward_dqn_list)/(Ns*M) # bps/Hz per link\n",
    "    return dqn_mean\n",
    "    \n",
    "def Test_episode(sess, episode):\n",
    "    reward_dqn_list = list()\n",
    "    H2_set, s_t = Initial_para()\n",
    "    for step_index in range(int(Ns)):\n",
    "        q_hat_ = sess.run(q_main, feed_dict={s: s_t})\n",
    "        p_t = power_set[np.argmax(q_hat_, axis = 1)] # W\n",
    "        s_next, r_ = Step(p_t, H2_set[:,:,step_index])\n",
    "        s_t = s_next\n",
    "        reward_dqn_list.append(r_)     \n",
    "    dqn_mean = sum(reward_dqn_list)/(Ns*M)\n",
    "    return dqn_mean\n",
    "    \n",
    "def Train(sess):\n",
    "    st = time.time()\n",
    "    dqn_hist = list() \n",
    "    for k in range(1, EPISODE+1):\n",
    "        dqn_hist.append(Train_episode(sess, k))        \n",
    "        if k % 100 == 0: \n",
    "            print(\"Episode(train):%d   DQN: %.3f   Time cost: %.2fs\" \n",
    "                  %(k, np.mean(dqn_hist[-100:]), time.time()-st))\n",
    "            st = time.time()\n",
    "    Save(weight_file) \n",
    "    return dqn_hist\n",
    "\n",
    "def Plot_gamma():\n",
    "    if flag_fig:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(6)\n",
    "        window = 201\n",
    "        hist = [os.getcwd() + '\\saved_networks\\hist_00',\n",
    "                os.getcwd() + '\\saved_networks\\hist_01',\n",
    "                os.getcwd() + '\\saved_networks\\hist_03',\n",
    "                os.getcwd() + '\\saved_networks\\hist_07',\n",
    "                os.getcwd() + '\\saved_networks\\hist_09']\n",
    "        y = list()\n",
    "        for k in range(5):\n",
    "            hist_data = scipy.io.loadmat(hist[k])['train_hist'][0]\n",
    "            y.append(Smooth(np.array(hist_data), window))\n",
    "        label=[r'$\\gamma = 0.0$',r'$\\gamma = 0.1$',r'$\\gamma = 0.3$',r'$\\gamma = 0.7$',r'$\\gamma = 0.9$']\n",
    "        color = ['royalblue', 'orangered', 'lawngreen', 'gold', 'olive']\n",
    "        linestyle = ['-', '--', '-.', ':', '--']\n",
    "        p = list()\n",
    "        for k in range(5):\n",
    "            p_temp, = plt.plot(range(EPISODE), y[k], color = color[k], linestyle = linestyle[k], label = label[k])\n",
    "            p.append(p_temp)\n",
    "        plt.legend(loc = 4)\n",
    "        plt.xlabel('Training Epoch')\n",
    "        plt.ylabel('Average rate (bps)')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "def Smooth(a, window):\n",
    "    a = np.concatenate((np.ones(window//2)*a[0], a, np.ones(window//2)*a[-1]))\n",
    "    out0 = np.convolve(a, np.ones(window, dtype=np.int32),'valid')/window\n",
    "    return out0\n",
    "     \n",
    "def Test(sess):\n",
    "    sess.run(load)\n",
    "    dqn_hist = list()\n",
    "    for k in range(1, TEST_EPISODE+1):\n",
    "        dqn_list = Test_episode(sess, k)\n",
    "        dqn_hist.append(np.mean(dqn_list))\n",
    "    return dqn_hist\n",
    "    \n",
    "def Save(weight_file):\n",
    "    dict_name={}\n",
    "    for var in list_main: \n",
    "        dict_name[var.name]=var.eval()\n",
    "    scipy.io.savemat(weight_file, dict_name)\n",
    "    \n",
    "def Network_ini(theta):\n",
    "    update=[]\n",
    "    for var in list_main:\n",
    "        update.append(tf.compat.v1.assign(tf.compat.v1.get_default_graph().get_tensor_by_name(var.name),tf.constant(np.reshape(theta[var.name],var.shape))))\n",
    "    return update\n",
    "    \n",
    "def Bar_plot_gamma(dqn_hist):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(4)\n",
    "    data = np.array(dqn_hist)      \n",
    "    data = np.array(data).T\n",
    "    name_list = ['N=25','N=49','N=100']\n",
    "    \n",
    "    num = len(data[0])\n",
    "    set_size = len(data)\n",
    "    total_width = 4.0\n",
    "    width = total_width / num\n",
    "    label=[r'$\\gamma = 0.0$',r'$\\gamma = 0.1$',r'$\\gamma = 0.3$',r'$\\gamma = 0.7$',r'$\\gamma = 0.9$']\n",
    "    color = ['royalblue', 'orangered', 'lawngreen', 'gold', 'olive']\n",
    "    x = np.linspace(0, 16, num = num, dtype = dtype)\n",
    "    plt.xticks(x+total_width/2+0.5, name_list)\n",
    "    bar = list()\n",
    "    for k in range(set_size):\n",
    "        bar.append(plt.bar(x, data[k], width = width, label = label[k],fc = color[k]))\n",
    "        x = x + width\n",
    "    for k in range(set_size): \n",
    "        for n in range(num):    \n",
    "            height = bar[k][n].get_height()\n",
    "            plt.text(bar[k][n].get_x() + bar[k][n].get_width()/2, height+0.01, '%.2f' %data[k][n], ha='center', va='bottom')\n",
    "    plt.legend(loc = 5)\n",
    "    plt.xlabel('Number of cells')\n",
    "    plt.ylabel('Average rate (bps)')\n",
    "    plt.show()   \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    n_x = 5\n",
    "    n_y = 5\n",
    "    N = n_x * n_y # BS number\n",
    "    M = N * maxM # maximum users\n",
    "    W_ = np.ones((M), dtype = dtype)         #[M]\n",
    "    Ns = 5e1\n",
    "    with tf.Graph().as_default():\n",
    "        H2 = tf.compat.v1.placeholder(shape = [None, K], dtype = dtype)\n",
    "        P = tf.compat.v1.placeholder(shape = [None], dtype = dtype)\n",
    "        W = tf.compat.v1.placeholder(shape = [None], dtype = dtype)\n",
    "        sigma2 = tf.compat.v1.placeholder(dtype = dtype)\n",
    "        p_array, p_list, user_list = Generate_environment()\n",
    "        rate_matrix, sinr_norm_inv, P_matrix, reward = Calculate_rate()\n",
    "    \n",
    "        s = tf.compat.v1.placeholder(shape = [None, state_num], dtype = dtype)\n",
    "        a = tf.compat.v1.placeholder(shape = [None, power_num], dtype = dtype)\n",
    "        y = tf.compat.v1.placeholder(shape = [None], dtype = dtype)\n",
    "        q_targ, a_targ, _, list_targ = Network(s, a, 'targ')\n",
    "        q_main, a_main, r, list_main = Network(s, a, 'main')\n",
    "        cost = Loss(y, r)\n",
    "        train_main, add_global = Optimizer(cost, list_main)\n",
    "        update = Network_update(list_main, list_targ)\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:        \n",
    "            tf.compat.v1.global_variables_initializer().run()  \n",
    "            train_hist = Train(sess)\n",
    "            scipy.io.savemat(hist_file, {'train_hist':train_hist})\n",
    "            \n",
    "\n",
    "        \n",
    "        weight = [os.getcwd() + '\\saved_networks\\dqn_00.mat',\n",
    "                  os.getcwd() + '\\saved_networks\\dqn_01.mat',\n",
    "                  os.getcwd() + '\\saved_networks\\dqn_03.mat',\n",
    "                  os.getcwd() + '\\saved_networks\\dqn_07.mat',\n",
    "                  os.getcwd() + '\\saved_networks\\dqn_09.mat']\n",
    "        \n",
    "        dqn_hist = list()         \n",
    "        num = [5,7,10]\n",
    "        for n in num: \n",
    "            n_x = n\n",
    "            n_y = n\n",
    "            N = n_x * n_y # BS number\n",
    "            M = N * maxM # maximum users\n",
    "            W_ = np.ones((M), dtype = dtype)         #[M]\n",
    "            \n",
    "            Ns = 1e3\n",
    "            TEST_EPISODE = 100\n",
    "            Ns = 4e1\n",
    "            TEST_EPISODE = 500\n",
    "                    \n",
    "            with tf.Graph().as_default():\n",
    "                H2 = tf.compat.v1.placeholder(shape = [None, K], dtype = dtype)\n",
    "                P = tf.compat.v1.placeholder(shape = [None], dtype = dtype)\n",
    "                W = tf.compat.v1.placeholder(shape = [None], dtype = dtype)\n",
    "                sigma2 = tf.compat.v1.placeholder(dtype = dtype)\n",
    "                p_array, p_list, user_list = Generate_environment()\n",
    "                rate_matrix, sinr_norm_inv, P_matrix, reward = Calculate_rate()\n",
    "            \n",
    "                s = tf.compat.v1.placeholder(shape = [None, state_num], dtype = dtype)\n",
    "                a = tf.compat.v1.placeholder(shape = [None, power_num], dtype = dtype)\n",
    "                q_main, a_main, r, list_main = Network(s, a, 'main')\n",
    "            \n",
    "            \n",
    "                dqn_hist_temp = list()\n",
    "                for k in range(5):\n",
    "                    load = Network_ini(scipy.io.loadmat(weight[k]))\n",
    "                    with tf.compat.v1.Session() as sess:        \n",
    "                        tf.compat.v1.global_variables_initializer().run()\n",
    "                        aa = np.mean(Test(sess))\n",
    "                        dqn_hist_temp.append(aa)\n",
    "                dqn_hist.append(dqn_hist_temp) \n",
    "        Plot_gamma()\n",
    "        Bar_plot_gamma(dqn_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T09:34:05.847298Z",
     "start_time": "2021-03-25T09:34:05.839819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
